{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding methods can be divided into two categories: \n",
    "\n",
    "(i) deterministic methods\n",
    "\n",
    "(ii) stochastic methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deteriminstic methods:\n",
    "\n",
    "Greedy search, beam search\n",
    "\n",
    "Generate text by selecting the text continuation with the highest likelihood measured by the LM.\n",
    "\n",
    "Often lead to the problem of model degeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of GPT2 and degeneration\n",
    "\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-large')\n",
    "input_ids = tokenizer('DeepMind Company is', return_tensors='pt').input_ids\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "\n",
    "output = model.generate(input_ids, max_length=128)\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(\"\" + 100 * '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to perform better, using :\n",
    "# top-k sampling, nucleus sampling (top-p)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-large')\n",
    "input_ids = tokenizer('DeepMind Company is', return_tensors='pt').input_ids\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "\n",
    "torch.manual_seed(0.)\n",
    "output = model.generate(input_ids, do_sample=True, max_length=128, top_p=0.95, top_k=0)\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(\"\" + 100 * '-')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastive Search\n",
    "\n",
    "Compare the generated token to all the previous tokens (with the hidden state), compute their consine similarity, if similar, then much penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DeepMind Company is a leader in artificial intelligence (AI). We have a long history of working with companies such as Google, Facebook, Amazon, and Microsoft to build products that improve people's lives, and today we are excited to announce that DeepMind's AlphaGo program has won the game of Go, becoming the first program to defeat a professional Go player.\n",
      "\n",
      "The victory is a testament to the power of deep learning, and to the incredible work of our research team, which has been at the forefront of AI research for the past five years. AlphaGo is one of the most advanced Go programs ever created, and its performance is an important step towards the goal of human-level AI.\n",
      "\n",
      "\"This is the culmination of a decade of hard work,\" said Andy Ng, co-founder and CTO of DeepMind. \"We are thrilled to have achieved this milestone and look forward to continuing to develop AI that can be used in a wide range of applications and to help people live better lives.\"\n",
      "\n",
      "DeepMind's work on Go began in 2010, when it began to train a neural network to play Go using millions of games played by top Go players around the world. Since then, the team has refined the algorithm, adding more and more layers of reinforcement learning to make it better at recognizing patterns and making decisions based on those patterns. In the past year and a half, the team has made significant progress in the game, winning a record-tying 13 games in a row to move into the top four of the world rankings.\n",
      "\n",
      "\"The game of Go is a complex game in which players have to be very careful not to overextend their territory, and this is something that we have been able to improve over and over again,\" said Dr. Demis Hassabis, co-founder and Chief Scientific Officer of DeepMind. \"We are very proud of our team's work, and we hope that it will inspire others to take the next step in their research and apply the same techniques to other problems.\"\n",
      "\n",
      "In addition to the win in Go, DeepMind has also developed an AI system that can learn to play a number of different games, including poker, Go, and chess. This AI system, called Tarsier, was developed in partnership with Carnegie Mellon University and the University of California, Berkeley, and is being used to teach computer vision and machine learning to identify objects in images and recognize speech in natural language. Tarsier has been trained to play the game of Go and other games on a\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# when penalty_alpha=0, it equal to greedy search.\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_name = 'gpt2-large'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "model.eval()\n",
    "\n",
    "# prepare the prefix\n",
    "prefix_text = r'DeepMind Company is'\n",
    "input_ids = tokenizer(prefix_text, return_tensors='pt').input_ids\n",
    "\n",
    "# generate the result with contrastive search\n",
    "output = model.generate(input_ids, penalty_alpha=0.6, top_k=4, max_length=512)\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(\"\" + 100 * '-')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

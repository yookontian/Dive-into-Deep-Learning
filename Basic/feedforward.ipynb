{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST\n",
    "\n",
    "DataLoader, Transformation\n",
    "\n",
    "Multilayer Neural Net, activation func\n",
    "\n",
    "Loss and optimizer\n",
    "\n",
    "Training loop (in-batch)\n",
    "\n",
    "model evaluation\n",
    "\n",
    "GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # images are 28x28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 28, 28]), torch.Size([100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "samples.shape, labels.shape\n",
    "# 100 images, only one color channel, resolution 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(net,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    # no softmax, because the loss_function do it for us\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function & optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch 1 / 2, step 100 / 600, loss = 0.2466\n",
      "eopch 1 / 2, step 200 / 600, loss = 0.1958\n",
      "eopch 1 / 2, step 300 / 600, loss = 0.1345\n",
      "eopch 1 / 2, step 400 / 600, loss = 0.1158\n",
      "eopch 1 / 2, step 500 / 600, loss = 0.2807\n",
      "eopch 1 / 2, step 600 / 600, loss = 0.1450\n",
      "eopch 2 / 2, step 100 / 600, loss = 0.0996\n",
      "eopch 2 / 2, step 200 / 600, loss = 0.0711\n",
      "eopch 2 / 2, step 300 / 600, loss = 0.1276\n",
      "eopch 2 / 2, step 400 / 600, loss = 0.0956\n",
      "eopch 2 / 2, step 500 / 600, loss = 0.1063\n",
      "eopch 2 / 2, step 600 / 600, loss = 0.0249\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_total_step = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape from (100, 1, 28, 28) to (100, 784)\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'eopch {epoch+1} / {num_epochs}, step {i+1} / {n_total_step}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 100.0 * n_correct / n_samples\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.1896,  -3.0678,  -2.1904,  -1.2334,  -2.2339,  -1.5244,  -2.0169,\n",
       "          -7.5558,   5.0661,  -5.8920],\n",
       "        [ -6.1538, -10.1403,  -7.0969,  -1.9766,   3.1817,  -4.7264,  -8.6740,\n",
       "          -2.2810,   0.7073,   4.9280],\n",
       "        [  6.7268,  -6.1161,  -0.0395,  -3.1222,  -2.6887,  -1.9964,  -2.1773,\n",
       "          -3.0343,  -2.5458,  -2.6893],\n",
       "        [ -7.1619,   4.9434,  -3.0896,  -3.2618,   0.5086,  -7.5520,  -5.8193,\n",
       "           0.6869,  -1.6224,  -4.9237],\n",
       "        [  1.2925,  -5.5986,   1.7396,  -0.0962,  -3.1651,  -0.7645,  -2.1003,\n",
       "          -2.7630,  -2.3324,  -6.8397]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21ee89defff7085579ccbc45d3f7bf353eb099fd9123e86b61fb4fca6d154f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# 0 data prepocessing\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "print(bc.keys())\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, the data will have zero mean and unit variance\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(-1, 1)\n",
    "y_test = y_test.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3618, -0.2652, -0.3172, -0.4671,  1.8038,  1.1817, -0.5169,  0.1065,\n",
       "         -0.3901,  1.3914,  0.1437, -0.1208,  0.1601, -0.1326, -0.5863, -0.1248,\n",
       "         -0.5787,  0.1091, -0.2819, -0.1889, -0.2571, -0.2403, -0.2442, -0.3669,\n",
       "          0.5449,  0.2481, -0.7109, -0.0797, -0.5280,  0.2506],\n",
       "        [-0.8633,  0.7156, -0.8565, -0.7967, -0.0586, -0.4285, -0.5170, -0.6814,\n",
       "          0.7948,  0.3882, -0.4545,  0.4009, -0.4357, -0.5216, -1.1631,  0.2724,\n",
       "          0.0675, -0.2392,  1.1130,  0.3502, -0.8894,  0.3847, -0.8880, -0.7897,\n",
       "         -1.0429, -0.4824, -0.5631, -0.7698,  0.4431, -0.2099],\n",
       "        [-0.4334,  0.3251, -0.4129, -0.5036,  0.2029,  0.3169,  0.2114,  0.2923,\n",
       "         -0.2941,  1.1295, -0.2249,  0.9890, -0.0743, -0.4596,  1.8909,  0.8176,\n",
       "          0.5919,  1.7726,  0.1356,  0.7924, -0.6160, -0.0636, -0.5528, -0.6284,\n",
       "         -0.1823, -0.1924, -0.2601, -0.0660, -1.1169,  0.0329],\n",
       "        [-0.4191,  1.0410, -0.3904, -0.4502,  1.1198,  0.4183,  0.2901,  0.5127,\n",
       "          0.3334,  0.4426,  0.0808, -0.1050,  0.0346, -0.0833,  0.2272,  0.0507,\n",
       "         -0.0820,  0.1819, -0.5122, -0.0746,  0.1686,  1.2218,  0.1297,  0.0124,\n",
       "          2.2445,  0.9297,  0.5803,  0.8613,  0.7972,  1.0085],\n",
       "        [-1.0237, -0.2420, -1.0508, -0.9044, -1.0732, -1.1425, -0.8710, -0.9779,\n",
       "          2.0571, -0.7337, -0.8157,  2.2826, -0.7971, -0.6329,  1.1806, -0.6738,\n",
       "         -0.3924, -0.1015, -0.4079,  0.2627, -1.1148, -0.4106, -1.1410, -0.9145,\n",
       "         -1.5058, -1.1813, -1.1047, -1.4059, -0.3344, -0.9030]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 model\n",
    "# f = wx + b, sigmoid at the end\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 loss and optimizer\n",
    "\n",
    "lr = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.7317\n",
      "epoch: 20, loss = 0.5813\n",
      "epoch: 30, loss = 0.4892\n",
      "epoch: 40, loss = 0.4275\n",
      "epoch: 50, loss = 0.3832\n",
      "epoch: 60, loss = 0.3499\n",
      "epoch: 70, loss = 0.3236\n",
      "epoch: 80, loss = 0.3024\n",
      "epoch: 90, loss = 0.2847\n",
      "epoch: 100, loss = 0.2698\n"
     ]
    }
   ],
   "source": [
    "# 3 training loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8022],\n",
      "        [0.9077],\n",
      "        [0.3040],\n",
      "        [0.8795],\n",
      "        [0.7495]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "accuracy = 0.8947\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    print(y_pred[:5])\n",
    "    y_pred_cls = y_pred.round()\n",
    "    print(y_pred_cls[:5])\n",
    "    acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21ee89defff7085579ccbc45d3f7bf353eb099fd9123e86b61fb4fca6d154f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

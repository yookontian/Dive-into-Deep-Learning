{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard to analyze and visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/mnist2\")  # identify a directory for saving results\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # images are 28x28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)   # 938 = 60000 // 64 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "samples.shape, labels.shape\n",
    "# 100 images, only one color channel, resolution 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAADACAYAAACkqgECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWF0lEQVR4nO3df2xV9f3H8fetthcs7S2FcUuVSrMAStzq0tDa4IC5xuoSAsqyORbj5pSIt25AHAtkgmFLSmSbQ1I121zLlrESYoAMMicr0O5Hi6NiNlatmsCog3uZ4L23dPSHvZ/vH8a71M/pl3N7Tz/nntvnIzl/9NVzzn2f7i17c/icU59SSgkAAIAhOW4XAAAAJheGDwAAYBTDBwAAMIrhAwAAGMXwAQAAjGL4AAAARjF8AAAAoxg+AACAUQwfAADAKIYPAABg1PUTdeLGxkbZsWOHhMNhqaiokF27dklVVdU1j0skEnL+/HkpKCgQn883UeUhyymlpK+vT0pLSyUnJ7UZm96Fm+hdeFVKvasmQEtLi8rLy1O//OUv1T//+U/16KOPqqKiIhWJRK55bG9vrxIRNjZHtt7eXnqXzZMbvcvm1c1O707I8FFVVaVCoVDy65GREVVaWqoaGhqueWw0GnX9B8eWPVs0GqV32Ty50btsXt3s9K7jaz6Ghoakq6tLamtrk1lOTo7U1tZKR0eHtv/g4KDE4/Hk1tfX53RJmMRSuYVM7yKT0LvwKju96/jw8f7778vIyIgEg8FReTAYlHA4rO3f0NAggUAguc2ZM8fpkgBb6F14Fb0Lr3H9aZdNmzZJLBZLbr29vW6XBNhC78Kr6F24zfGnXWbOnCnXXXedRCKRUXkkEpGSkhJtf7/fL36/3+kygJTRu/Aqehde4/idj7y8PKmsrJTW1tZklkgkpLW1VWpqapz+OMAx9C68it6F56S0nNqmlpYW5ff7VXNzs+ru7lZr1qxRRUVFKhwOX/PYWCzm+kpdtuzZYrEYvcvmyY3eZfPqZqd3J2T4UEqpXbt2qbKyMpWXl6eqqqpUZ2enreP4j4DNyS3VP8DpXbZM2ehdNq9udnrXp5RSkkHi8bgEAgG3y0CWiMViUlhYaOSz6F04id6FV9npXdefdgEAAJMLwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKMYPgAAgFEMHwAAwCiGDwAAYBTDBwAAMIrhAwAAGHW92wVgtPz8fC379re/rWU33HCDlt11111adscdd9j+7Oeff17LnnjiCdvHAwBgB3c+AACAUQwfAADAKIYPAABgFMMHAAAwigWnBvj9fi178sknLffdsGGDlgUCAVuf4/P5tEwpZetYEZEvf/nLWtbY2Khlb731lu1zAia89tprWjZr1iwtmzt3roFqAFwLdz4AAIBRDB8AAMAohg8AAGAUwwcAADCKBacG/OhHP9KytWvX2j7+zJkzWjYyMqJlbW1tWtbR0WF5zi996UtaFgwGtayvr89OiYAx1dXVWvbZz35Wy44fP26gGgDjwZ0PAABgFMMHAAAwiuEDAAAYxfABAACMYsGpAVaL4VJx5513alkkEknrnM3NzWkdD0y0vLw8y/wXv/iFluXm5mrZ3r17Ha8J6SspKdGye+65x/bxGzdu1LIFCxZomdWbmC9dumR5zs9//vNadvHiRS373ve+Z6fEMfHn7v9w5wMAABjF8AEAAIxi+AAAAEYxfAAAAKMYPgAAgFE87ZJhjhw5omXRaNR8IYDL1qxZY5kvXLhQy/7whz9oWVNTk+M1YWxWT7Hs2bNHywKBgJZZPRGYk2P9d+NEImErmz9/vuXxds9ZXFysZT//+c9tn9OK1c9o+/btaZ3Tq7jzAQAAjGL4AAAARjF8AAAAoxg+AACAUSw4dZjVIqXp06fbPv69997TssHBwbRqArzokUcesb3vunXrJq4Q2DIwMKBlVgs50/11E172la98RctaWlq07OzZswaqcRd3PgAAgFEMHwAAwCiGDwAAYFTKw0d7e7ssX75cSktLxefzyYEDB0Z9XyklW7ZskdmzZ8vUqVOltrZW3nnnHafqBcaN3oVX0bvINikvOO3v75eKigp5+OGH5f7779e+/8wzz8hzzz0nu3fvlvLycnnqqaekrq5Ouru7ZcqUKY4Uncms3r5olY2FtzJOHHr3f9auXatln/70p7Vs8+bNWjY0NOR4PevXr9eysRYm7tu3T8vefvttx2vKJF7oXas3Mf/617+2dexLL72kZX/9618t9924caOWLViwwNZ+ly5dslVPKtrb27WstLTUct+Kigot27t3r5ZVV1enX1iGS3n4uPfee+Xee++1/J5SSn7605/K97//fVmxYoWIiPzqV7+SYDAoBw4ckAceeCC9aoE00LvwKnoX2cbRNR9nzpyRcDgstbW1ySwQCEh1dbV0dHRYHjM4OCjxeHzUBphG78Kr6F14kaPDRzgcFhGRYDA4Kg8Gg8nvfVJDQ4MEAoHkNmfOHCdLAmyhd+FV9C68yPWnXTZt2iSxWCy59fb2ul0SYAu9C6+id+E2R99w+vGvC45EIjJ79uxkHolE5Pbbb7c8xu/3i9/vd7IMV1ktKLLy+9//3jL/29/+5mQ5sGmy9e6SJUu07Ktf/aqWzZs3T8usFquKiJw/f97WZ1stgHzwwQe1TCllefyuXbtsfc5kkcm9u3v3bltZKkKhUFrHO+1nP/uZlj399NO2j58xY4aD1XiHo3c+ysvLpaSkRFpbW5NZPB6XEydOSE1NjZMfBTiK3oVX0bvwopTvfFy5ckXefffd5NdnzpyRN954Q4qLi6WsrEzWrVsnP/zhD2XevHnJR75KS0tl5cqVTtYNpIzehVfRu8g2KQ8fJ0+elC984QvJrzds2CAiIg899JA0NzfLxo0bpb+/X9asWSPRaFTuvPNOeeWVV7LuPQnwHnoXXkXvItukPHwsW7ZszH+LFRHx+Xyybds22bZtW1qFAU6jd+FV9C6yjetPuwAAgMnF0addJptPfepTWvbYY4/ZOvbKlSuW+fDwcFo1fdLSpUst87FeXf1JVk8wvPzyy2nVBPdZvRI6Ly9Py5YvX65lPT09lue0yl944QUtmzt3rpZZPSW2Z88ey8/p7Oy0zAE3+Hw+LcvJsf57vVVudfxkwJ0PAABgFMMHAAAwiuEDAAAYxfABAACMYsFpGm688UYtu/XWW4189pNPPqllW7Zs0bLc3FzL48fKP2lkZETLNm/erGU//vGPbZ0PmWHv3r1aZrU41OpV1mMtqv7c5z6nZVavnrZaYGf1GGkkErH8HKvXgn/44YeW+wIT7Zvf/KaWJRIJ28f/f49QZzPufAAAAKMYPgAAgFEMHwAAwCiGDwAAYBQLTh1m9211Y71h9Ac/+IGWfec739Gy/Px8LbN6e57VglERkf7+fi2z+iVU11+vt4jVgsOx3kZ54cIFyxzuunz5sq39GhsbtcxqYaqI9dt0t27dqmVLliyx9dnLli2zzG+++WYt6+7utnVOINMUFRVpmdV/S21tbQaqMYc7HwAAwCiGDwAAYBTDBwAAMIrhAwAAGMWCU4fZfVvdggULLPNNmzbZOv7KlStadujQIS374x//aHl8U1OTlj3yyCNa9uKLL2pZeXm5lgWDQcvPYcFp9hnr7Y3Hjh3TsgcffFDLrBbTrV+/Xst27tw5juoAszZu3KhlLS0tto8PBAJaxoJTAAAAhzF8AAAAoxg+AACAUQwfAADAKBacZph4PK5lhw8f1rJnn31Wy15//fW0PrukpMTWfv/4xz+07Ny5c2l9Nrxv/vz5WrZ69Wot++CDD7RsrDfkApnu0qVLbpfgSdz5AAAARjF8AAAAoxg+AACAUQwfAADAKIYPAABgFE+7pOHs2bNa9t3vflfLvv71r2vZm2++aXlOq1dKnzx5MvXirmH27Nla9uijj9o6tqurS8suX76cdk3wtmnTpmlZbm6ulu3bt0/L/vOf/0xITYAbcnKs/14/Vj4Z8ZMAAABGMXwAAACjGD4AAIBRDB8AAMAoFpymIRqNapnVa8+tMrc9/PDDWnbjjTfaOra5udnhapAN7rvvPlv7vf322xNcCeCuRCIxIftmE+58AAAAoxg+AACAUQwfAADAKIYPAABgFAtOs1xVVZVlHgqFbB3/wQcf2MqApUuX2trvrbfemuBKAGQ67nwAAACjGD4AAIBRDB8AAMColIaPhoYGWbRokRQUFMisWbNk5cqV0tPTM2qfgYEBCYVCMmPGDJk2bZqsWrVKIpGIo0UDqaJ34VX0LrKRTyml7O58zz33yAMPPCCLFi2SDz/8UDZv3iynT5+W7u5uyc/PFxGRtWvXyuHDh6W5uVkCgYDU19dLTk6O/OUvf7H1GfF4XAKBwPiuZpKrrKzUssOHD1vuO3PmTC2zemPr6tWrtezVV19NvTiXxGIxKSwspHcdVFRUZJlfvnzZ1vH8WnF76F1vWLZsmZYdOXLEcl+r3j937pyW3X777VoWi8VSrs0tH/fu/yelp11eeeWVUV83NzfLrFmzpKurS5YsWSKxWExeeukl2bNnj9x1110iItLU1CS33nqrdHZ2yh133JHiJQDOoHfhVfQuslFafwX5eBIrLi4WEZGuri4ZHh6W2tra5D633HKLlJWVSUdHh+U5BgcHJR6Pj9qAiUbvwqvoXWSDcQ8fiURC1q1bJ4sXL5bbbrtNRETC4bDk5eVpt2WDwaCEw2HL8zQ0NEggEEhuc+bMGW9JgC30LryK3kW2GPfwEQqF5PTp09LS0pJWAZs2bZJYLJbcent70zofcC30LryK3kW2GNcbTuvr6+XQoUPS3t4uN910UzIvKSmRoaEhiUajo6bwSCQiJSUllufy+/3i9/vHU4brFi5cqGX79+/Xst/85jda9qc//cnynP/+97+1bPHixVpWU1OjZatWrdKysRaRWd1m/drXvqZlYy2c8ip6N30DAwOW+dmzZ7Xs5ptvnuBqJg96NzuNjIxomZcWl45XSnc+lFJSX18v+/fvl6NHj0p5efmo71dWVkpubq60trYms56eHjl37pzl/1kCptC78Cp6F9kopTsfoVBI9uzZIwcPHpSCgoLkvycGAgGZOnWqBAIB+da3viUbNmyQ4uJiKSwslCeeeEJqampYcQ1X0bvwKnoX2Sil4eOFF14QEf255qamJvnGN74hIiLPPvus5OTkyKpVq2RwcFDq6urk+eefd6RYYLzoXXgVvYtslNLwYed9ZFOmTJHGxkZpbGwcd1GA0+hdeBW9i2zEqwYBAIBR43raBR+xemLk+uv1H+mWLVu07OrVq5bnHB4e1rJrvab2Yz6fT8v6+/st97V6MubYsWO2PgeTW7pPu+Tm5mqZVd8DXjXWrxCwyq3+3J4MuPMBAACMYvgAAABGMXwAAACjGD4AAIBRLDhNw3vvvadldXV1WrZt2zYt+8xnPmN5zrFeh2xHW1ublj399NOW+7a3t4/7cwArL7/8spYtXbpUyx5//HEt27lz54TUBLghkUjY3nf79u0TWEnm4s4HAAAwiuEDAAAYxfABAACMYvgAAABGseDUYe+++66WrV692oVKALNaWlq0LBQKadn06dNNlAMYsWLFCtv7vvHGG1r26quvOliNd3DnAwAAGMXwAQAAjGL4AAAARjF8AAAAo1hwCsARly5d0rKFCxe6UAlgzvz5823vO2/ePC1btmyZlu3evTudkjyBOx8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIziaRcAAMZpx44dWnb33Xdb7pufn69lO3fu1LJoNKplBw8eTL24DMadDwAAYBTDBwAAMIrhAwAAGMXwAQAAjGLBKQAA43T8+HEty83NNV+Ix3DnAwAAGMXwAQAAjGL4AAAARmXc8KGUcrsEZBGT/UTvwkn0LrzKTj9l3PDR19fndgnIIib7id6Fk+hdeJWdfvKpDBt5E4mEnD9/XgoKCqSvr0/mzJkjvb29UlhY6HZpaYvH41yPIUop6evrk9LSUsnJMTNj07vekcnXQ+86K5P/tx6PTL6eVHo34x61zcnJkZtuuklERHw+n4iIFBYWZtwPOR1cjxmBQMDo59G73pOp10PvOo/rMcNu72bcP7sAAIDsxvABAACMyujhw+/3y9atW8Xv97tdiiO4nskj2342XM/kkW0/G64nM2XcglMAAJDdMvrOBwAAyD4MHwAAwCiGDwAAYBTDBwAAMCpjh4/GxkaZO3euTJkyRaqrq+W1115zuyTb2tvbZfny5VJaWio+n08OHDgw6vtKKdmyZYvMnj1bpk6dKrW1tfLOO++4U+w1NDQ0yKJFi6SgoEBmzZolK1eulJ6enlH7DAwMSCgUkhkzZsi0adNk1apVEolEXKo4M3i1f+ldepfezQzZ3r8ZOXzs3btXNmzYIFu3bpXXX39dKioqpK6uTi5evOh2abb09/dLRUWFNDY2Wn7/mWeekeeee05efPFFOXHihOTn50tdXZ0MDAwYrvTa2traJBQKSWdnpxw5ckSGh4fl7rvvlv7+/uQ+69evl9/97neyb98+aWtrk/Pnz8v999/vYtXu8nL/0rv0Lr2bGbK+f1UGqqqqUqFQKPn1yMiIKi0tVQ0NDS5WNT4iovbv35/8OpFIqJKSErVjx45kFo1Gld/vV7/97W9dqDA1Fy9eVCKi2tralFIf1Z6bm6v27duX3OfNN99UIqI6OjrcKtNV2dK/9O7kQ+9mrmzr34y78zE0NCRdXV1SW1ubzHJycqS2tlY6OjpcrMwZZ86ckXA4POr6AoGAVFdXe+L6YrGYiIgUFxeLiEhXV5cMDw+Pup5bbrlFysrKPHE9Tsvm/qV3sxu9m9myrX8zbvh4//33ZWRkRILB4Kg8GAxKOBx2qSrnfHwNXry+RCIh69atk8WLF8ttt90mIh9dT15enhQVFY3a1wvXMxGyuX/p3exG72aubOzfjPuttshcoVBITp8+LX/+85/dLgVICb0LL8vG/s24Ox8zZ86U6667TluxG4lEpKSkxKWqnPPxNXjt+urr6+XQoUNy7Nix5K/eFvnoeoaGhiQajY7aP9OvZ6Jkc//Su9mN3s1M2dq/GTd85OXlSWVlpbS2tiazRCIhra2tUlNT42JlzigvL5eSkpJR1xePx+XEiRMZeX1KKamvr5f9+/fL0aNHpby8fNT3KysrJTc3d9T19PT0yLlz5zLyeiZaNvcvvZvd6N3MkvX96/KCV0stLS3K7/er5uZm1d3drdasWaOKiopUOBx2uzRb+vr61KlTp9SpU6eUiKif/OQn6tSpU+pf//qXUkqp7du3q6KiInXw4EH197//Xa1YsUKVl5erq1evuly5bu3atSoQCKjjx4+rCxcuJLf//ve/yX0ee+wxVVZWpo4ePapOnjypampqVE1NjYtVu8vL/Uvv0rv0bmbI9v7NyOFDKaV27dqlysrKVF5enqqqqlKdnZ1ul2TbsWPHlIho20MPPaSU+uixr6eeekoFg0Hl9/vVF7/4RdXT0+Nu0WOwug4RUU1NTcl9rl69qh5//HE1ffp0dcMNN6j77rtPXbhwwb2iM4BX+5fepXfp3cyQ7f3rU0qpib23AgAA8D8Zt+YDAABkN4YPAABgFMMHAAAwiuEDAAAYxfABAACMYvgAAABGMXwAAACjGD4AAIBRDB8AAMAohg8AAGAUwwcAADCK4QMAABj1f5i2jfW36hN/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "# create a grid and write it into writer\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()  # make sure all the output get flushed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(net,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    # no softmax, because the loss_function do it for us\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function & optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "# model graph\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28).to(device))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch 1 / 1, step 100 / 938, loss = 0.4407\n",
      "eopch 1 / 1, step 200 / 938, loss = 0.3501\n",
      "eopch 1 / 1, step 300 / 938, loss = 0.1977\n",
      "eopch 1 / 1, step 400 / 938, loss = 0.0806\n",
      "eopch 1 / 1, step 500 / 938, loss = 0.2699\n",
      "eopch 1 / 1, step 600 / 938, loss = 0.3355\n",
      "eopch 1 / 1, step 700 / 938, loss = 0.0421\n",
      "eopch 1 / 1, step 800 / 938, loss = 0.1670\n",
      "eopch 1 / 1, step 900 / 938, loss = 0.0775\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_total_step = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape from (100, 1, 28, 28) to (100, 784)\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, prediction = torch.max(pred, 1)\n",
    "        running_correct += (prediction == labels).sum().item()\n",
    "\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'eopch {epoch+1} / {num_epochs}, step {i+1} / {n_total_step}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_step + i)\n",
    "            writer.add_scalar('acc', running_correct / 100, epoch * n_total_step + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a recall curve\n",
    "\n",
    "pred_label = []\n",
    "pred_logits = []\n",
    "\n",
    "# test\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()\n",
    "\n",
    "        output_logits = [nn.functional.softmax(o, dim=0) for o in output]\n",
    "        pred_logits.append(output_logits)\n",
    "        pred_label.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logits = torch.cat([torch.stack(batch) for batch in pred_logits])\n",
    "pred_label = torch.cat(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]), torch.Size([10000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits.shape, pred_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc of the network on the test :95.46 %\n"
     ]
    }
   ],
   "source": [
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Acc of the network on the test :{acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label[:2] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n",
      "tensor([False, False, False,  ..., False, False, False], device='cuda:0')    tensor([6.2710e-08, 9.4496e-15, 9.9134e-10,  ..., 5.8368e-13, 5.0057e-05,\n",
      "        3.1711e-07], device='cuda:0')\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n",
      "tensor([False, False,  True,  ..., False, False, False], device='cuda:0')    tensor([7.4163e-08, 6.5887e-04, 9.9998e-01,  ..., 3.1572e-07, 9.6078e-07,\n",
      "        5.0968e-10], device='cuda:0')\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n",
      "tensor([False,  True, False,  ..., False, False, False], device='cuda:0')    tensor([1.5293e-05, 9.9932e-01, 6.3492e-07,  ..., 6.8693e-12, 2.3208e-10,\n",
      "        2.8662e-07], device='cuda:0')\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n",
      "tensor([False, False, False,  ..., False, False, False], device='cuda:0')    tensor([7.6817e-06, 2.3126e-05, 4.3919e-08,  ..., 6.7951e-09, 2.9844e-04,\n",
      "        2.0305e-04], device='cuda:0')\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n",
      "tensor([False, False, False,  ...,  True, False, False], device='cuda:0')    tensor([1.4200e-10, 4.4791e-13, 3.9936e-06,  ..., 1.0000e+00, 4.3225e-07,\n",
      "        1.1460e-04], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in range(num_classes):\n",
    "    labels_i = pred_label == i\n",
    "    preds_i = pred_logits[:, i]\n",
    "    if n < 5:\n",
    "        print(pred_label)\n",
    "        print(labels_i, \"  \", preds_i)\n",
    "    writer.add_pr_curve(str(train_dataset.classes[i]), labels_i, preds_i, global_step=0)\n",
    "    writer.close()\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21ee89defff7085579ccbc45d3f7bf353eb099fd9123e86b61fb4fca6d154f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

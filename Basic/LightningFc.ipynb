{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Lightning is a wrapper for ML researchers, to write less boilerplate.\n",
    "\n",
    "1. don't have to set model.train() or model.eval() mode\n",
    "\n",
    "2. don't have to worry about device, easily turn up gpu or tpu\n",
    "\n",
    "3. no loss.backward() and optimizer.zero_grad()\n",
    "\n",
    "4. no torch.zero_grad() and torch.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/anaconda3/envs/d2l/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import Trainer as light_trainer\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyperparameters\"\"\"\n",
    "\n",
    "input_size = 784 # images are 28x28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = iter(test_loader)\n",
    "# samples, labels = next(examples)\n",
    "# samples.shape, labels.shape\n",
    "# 100 images, only one color channel, resolution 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     plt.subplot(1, 3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap='gray')\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pl.LightningModule instead of nn.Module\"\"\"\n",
    "\n",
    "\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LitNet,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    # no softmax, because the loss_function do it for us\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(images)\n",
    "        loss = F.cross_entropy(y_hat, labels)\n",
    "\n",
    "        # Navagate the lightning_logs on tensorboard\n",
    "        # tensorboard_logs = {'train_loss': loss} \n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {'loss': loss}\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "        return train_loader\n",
    "    \n",
    "\n",
    "    # using the test dataset for validation dataset\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(images)\n",
    "        loss = F.cross_entropy(y_hat, labels)\n",
    "        \n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size,num_workers=4, shuffle=False)\n",
    "\n",
    "        return val_loader\n",
    "    \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "\n",
    "        # Navagate the lightning_logs on tensorboard\n",
    "        # tensorboard_logs = {'val_losss': avg_loss}\n",
    "        self.log(\"validation_loss\", avg_loss)\n",
    "        return {'val_loss': avg_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 392 K \n",
      "1 | relu | ReLU   | 0     \n",
      "2 | l2   | Linear | 5.0 K \n",
      "--------------------------------\n",
      "397 K     Trainable params\n",
      "0         Non-trainable params\n",
      "397 K     Total params\n",
      "1.590     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd412d17d4a4b02884ff5075b9321a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe0f627b73c4c80a188bab2a719e267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3313a29bee9740f49707a3d24a1e242e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94185c99801643a5a442fc2e672c6c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "model = LitNet(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)\n",
    "trainer = light_trainer(auto_lr_find=True, max_epochs=num_epochs,fast_dev_run=False, accelerator='gpu', devices=1)  # fast_dev_run will run a single batch to training, to test the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = net(input_size, hidden_size, num_classes)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function & optimizer\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "# n_total_step = len(train_loader)\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         # reshape from (100, 1, 28, 28) to (100, 784)\n",
    "#         images = images.reshape(-1, 28*28).to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # forward pass\n",
    "#         pred = model(images)\n",
    "#         loss = criterion(pred, labels)\n",
    "\n",
    "#         # backward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print(f'eopch {epoch+1} / {num_epochs}, step {i+1} / {n_total_step}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, 28*28).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         output = model(images)\n",
    "\n",
    "#         _, pred = torch.max(output, 1)\n",
    "#         n_samples += labels.shape[0]\n",
    "#         n_correct += (pred == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = 100.0 * n_correct / n_samples\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Navagate the lightning_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21ee89defff7085579ccbc45d3f7bf353eb099fd9123e86b61fb4fca6d154f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(arg, PATH)\n",
    "\n",
    "torch.load(PATH)\n",
    "\n",
    "model.load_state_dict(arg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model\n",
    "\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# Load\n",
    "\n",
    "model = torch.load(PATH)\n",
    "\n",
    "[set model to eval mode]\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save para directly\n",
    "\n",
    "[Save all the parameters]\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "#Load\n",
    "\n",
    "[need to define a model first]\n",
    "\n",
    "model = Model(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.l1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=10)\n",
    "FILE = 'm/model.pth'\n",
    "FILE2 = 'm/model_state.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learninig_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learninig_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy method (larger size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.load(FILE)\n",
    "m1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0258,  0.2678,  0.2451,  0.2652,  0.0178, -0.1142,  0.3051, -0.2506,\n",
      "         -0.0194,  0.1107]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2239], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in m1.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferable method (smaller size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),FILE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = Model(input_size=10)\n",
    "m2.load_state_dict(torch.load(FILE2))\n",
    "m2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0258,  0.2678,  0.2451,  0.2652,  0.0178, -0.1142,  0.3051, -0.2506,\n",
      "         -0.0194,  0.1107]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2239], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in m2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('l1.weight', tensor([[-0.0258,  0.2678,  0.2451,  0.2652,  0.0178, -0.1142,  0.3051, -0.2506,\n",
      "         -0.0194,  0.1107]])), ('l1.bias', tensor([0.2239]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"epoch\": 90,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optim_state\": optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "num_epoch = 8\n",
    "torch.save(checkpoint, f\"m/checkpoint-{num_epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_checkpoint = torch.load(f\"m/checkpoint-{num_epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = m_checkpoint['epoch']\n",
    "model_checkpoint = Model(input_size=10)\n",
    "optimizer_c = torch.optim.SGD(model_checkpoint.parameters(), lr=0)\n",
    "\n",
    "model_checkpoint.load_state_dict(m_checkpoint['model_state'])\n",
    "optimizer_c.load_state_dict(checkpoint['optim_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(optimizer_c.state_dict() == optimizer.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on GPU and saved, but load on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpu = Model(input_size=10).to(device)\n",
    "torch.save(model_gpu.state_dict(), \"m/ModelGPU.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "m_cpu = Model(input_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_cpu.load_state_dict(torch.load(\"m/ModelGPU.pth\", map_location=cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('l1.weight', tensor([[ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
      "          0.1865,  0.1716]], device='cuda:0')), ('l1.bias', tensor([-0.0463], device='cuda:0'))])\n",
      "OrderedDict([('l1.weight', tensor([[ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
      "          0.1865,  0.1716]])), ('l1.bias', tensor([-0.0463]))])\n"
     ]
    }
   ],
   "source": [
    "print(model_gpu.state_dict())\n",
    "print(m_cpu.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save on GPU, load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu = Model(input_size=10)\n",
    "m_gpu.load_state_dict(torch.load(\"m/ModelGPU.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('l1.weight',\n",
       "              tensor([[ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
       "                        0.1865,  0.1716]])),\n",
       "             ('l1.bias', tensor([-0.0463]))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get para of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(m_gpu.named_parameters())\n",
    "b = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.parameter.Parameter,\n",
       " Parameter containing:\n",
       " tensor([[ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
       "           0.1865,  0.1716]], requires_grad=True))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b[1]), b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor,\n",
       " tensor([ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
       "          0.1865,  0.1716], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b[1].__getitem__(0)), b[1].__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2037, -0.0217,  0.0297,  0.0653,  0.1367, -0.2099,  0.3075, -0.0286,\n",
       "         0.1865,  0.1716], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu.l1.weight.__getitem__(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a866008e9c64825bf1936b2d634634baf6fd4d0ab36469510d6409c17d9a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

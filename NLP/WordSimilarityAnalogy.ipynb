{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/anaconda3/envs/d2l/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
    "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
    "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
    "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "    def __init__(self, embedding_name):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = d2l.download_extract(embedding_name)\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec    # +: concatenate, not adding\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_6b50d = TokenEmbedding('glove.6b.50d')\n",
    "len(glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103,\n",
       " tensor([ 0.4532,  0.0598, -0.1058, -0.3330,  0.7236, -0.0872, -0.6105, -0.0377,\n",
       "         -0.3095,  0.2181, -0.4360,  0.4732, -0.7687, -0.2713,  1.1042,  0.5914,\n",
       "          0.5696, -0.1868,  0.1487, -0.6729, -0.3467,  0.5228,  0.2296, -0.0720,\n",
       "          0.9397, -2.3985, -1.3238,  0.2870,  0.7551, -0.7652,  3.3425,  0.1723,\n",
       "         -0.5180, -0.8297, -0.2933, -0.5008, -0.1523,  0.0990,  0.1815, -0.1742,\n",
       "         -0.4067,  0.2035, -0.0118,  0.4825,  0.0246,  0.3406, -0.0847,  0.5324,\n",
       "         -0.2510,  0.6255]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_6b50d.token_to_idx['what'], glove_6b50d.idx_to_vec[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(k, word, data):\n",
    "    word_vector = torch.tensor(data.idx_to_vec[data.token_to_idx[word]])\n",
    "    W = torch.tensor(data.idx_to_vec)\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    # torch.mv : Performs a matrix-vector product of the matrix input and the vector vec.\n",
    "    cos = torch.mv(W, word_vector) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      (torch.sum(word_vector * word_vector) + 1e-9))\n",
    "    topk = torch.topk(cos, k=k+1)[1]\n",
    "    for i in topk[2:]:  # 0is the <unk> with nan similarity, 1 is input word\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {data.idx_to_token[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, word, data):\n",
    "    word_vector = word\n",
    "    W = torch.tensor(data.idx_to_vec)\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    # torch.mv : Performs a matrix-vector product of the matrix input and the vector vec.\n",
    "    cos = torch.mv(W, word_vector) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      (torch.sum(word_vector * word_vector) + 1e-9))\n",
    "    topk = torch.topk(cos, k=k+1)[1]\n",
    "    return topk[2:], [cos[int(i)] for i in topk[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.886: woman\n",
      "cosine sim=0.856: boy\n",
      "cosine sim=0.845: another\n",
      "cosine sim=0.837: old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/1667884341.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vector = torch.tensor(data.idx_to_vec[data.token_to_idx[word]])\n",
      "/tmp/ipykernel_81253/1667884341.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens(5, 'man', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/3120575760.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  word_vector = torch.tensor(data.idx_to_vec[data.token_to_idx[word]])\n",
      "/tmp/ipykernel_81253/3120575760.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 788, 1607,  171,  168]),\n",
       " [tensor(0.8860), tensor(0.8564), tensor(0.8453), tensor(0.8372)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn(5, 'man', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = [embed.idx_to_vec[embed.token_to_idx[token_a]],\n",
    "            embed.idx_to_vec[embed.token_to_idx[token_b]],\n",
    "            embed.idx_to_vec[embed.token_to_idx[token_c]]\n",
    "            ]\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(3, x, embed)\n",
    "    return embed.idx_to_token[int(topk[0])]  # Remove unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/1558377015.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mother'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'son', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/1558377015.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tokyo'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/1558377015.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'worst'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81253/1558377015.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  W = torch.tensor(data.idx_to_vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'before'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('do', 'did', 'go', glove_6b50d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
